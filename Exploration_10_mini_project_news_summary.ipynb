{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wired-rebound",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "optimum-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compound-trial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92057</th>\n",
       "      <td>Andhra police raid YSR Cong office over 'offen...</td>\n",
       "      <td>The Andhra Pradesh Police has conducted search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28335</th>\n",
       "      <td>Teaser of Sonam, Anil's Ek Ladki Ko Dekha Toh ...</td>\n",
       "      <td>The teaser of Sonam Kapoor and Anil Kapoor sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88684</th>\n",
       "      <td>UP village panchayat orders rape victim to mar...</td>\n",
       "      <td>The panchayat of a village in Uttar Pradesh's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46039</th>\n",
       "      <td>India is the economic hope of the globe: Vice ...</td>\n",
       "      <td>While presenting the Prime Minister's Shram Aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>Drunk cab driver drives without front tyre, hi...</td>\n",
       "      <td>A video of an incident has surfaced online, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65594</th>\n",
       "      <td>Ex-President Kalam missed becoming an IAF pilo...</td>\n",
       "      <td>Former President Dr APJ Abdul Kalam had studie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31243</th>\n",
       "      <td>CSK end SRH's 6-game winning streak as Rayudu ...</td>\n",
       "      <td>CSK on Sunday registered an eight-wicket victo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77833</th>\n",
       "      <td>We look forward to the results of the Snapdeal...</td>\n",
       "      <td>A SoftBank spokesperson said that the company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>Bhopal to become India's first city to have cr...</td>\n",
       "      <td>India's first crematorium for cows, named 'gau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29183</th>\n",
       "      <td>Two girls hit by train in Delhi, 'sorry father...</td>\n",
       "      <td>Two girls were hit by a train in Delhi and dec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "92057  Andhra police raid YSR Cong office over 'offen...   \n",
       "28335  Teaser of Sonam, Anil's Ek Ladki Ko Dekha Toh ...   \n",
       "88684  UP village panchayat orders rape victim to mar...   \n",
       "46039  India is the economic hope of the globe: Vice ...   \n",
       "9911   Drunk cab driver drives without front tyre, hi...   \n",
       "65594  Ex-President Kalam missed becoming an IAF pilo...   \n",
       "31243  CSK end SRH's 6-game winning streak as Rayudu ...   \n",
       "77833  We look forward to the results of the Snapdeal...   \n",
       "1582   Bhopal to become India's first city to have cr...   \n",
       "29183  Two girls hit by train in Delhi, 'sorry father...   \n",
       "\n",
       "                                                    text  \n",
       "92057  The Andhra Pradesh Police has conducted search...  \n",
       "28335  The teaser of Sonam Kapoor and Anil Kapoor sta...  \n",
       "88684  The panchayat of a village in Uttar Pradesh's ...  \n",
       "46039  While presenting the Prime Minister's Shram Aw...  \n",
       "9911   A video of an incident has surfaced online, wh...  \n",
       "65594  Former President Dr APJ Abdul Kalam had studie...  \n",
       "31243  CSK on Sunday registered an eight-wicket victo...  \n",
       "77833  A SoftBank spokesperson said that the company ...  \n",
       "1582   India's first crematorium for cows, named 'gau...  \n",
       "29183  Two girls were hit by a train in Delhi and dec...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-trash",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-party",
   "metadata": {},
   "source": [
    "## 중복값 제거 및 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sonic-airplane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98360"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "immune-economy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98280"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['headlines'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ambient-position",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98360"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복값 제거하기\n",
    "\n",
    "data.drop_duplicates(subset = ['text'], inplace = True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "velvet-cricket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null값 확인\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-steps",
   "metadata": {},
   "source": [
    "## 텍스트 정규화, 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "qualified-orange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 정규화 사전\n",
    "\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mysterious-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# 불용어 사전 확인\n",
    "\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "civil-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exterior-dimension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426.1433460712433  seconds\n",
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers'\n",
      " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit'\n",
      " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history'\n",
      " ...\n",
      " 'according reports new version science fiction film matrix development michael jordan reportedly play lead role film screenwriter zak penn talks write script film reports added actor keanu reeves starred original film followed two sequels'\n",
      " 'new music video shows rapper snoop dogg aiming toy gun clown character parodying us president donald trump video also shows tv airing news conference headline ronald klump wants deport doggs airing live clown house video remixed version song lavender'\n",
      " 'madhesi morcha alliance seven political parties withdrawn support pm pushpa kamal dahal led nepal government failed meet seven day ultimatum fulfil demands including endorsement revised constitution amendment bill morcha seats parliament despite withdrawal support immediate threat government']\n",
      "12.696515321731567  seconds\n",
      "['upgrad learner switches to career in ml al with salary hike'\n",
      " 'delhi techie wins free food from swiggy for one year on cred'\n",
      " 'new zealand end rohit sharma led india match winning streak' ...\n",
      " 'the matrix film to get reboot reports'\n",
      " 'snoop dogg aims gun at clown dressed as trump in new video'\n",
      " 'madhesi morcha withdraws support to nepalese government']\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp   # 멀티 프로세싱으로 전처리 속도를 획기적으로 줄여봅시다\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  # map을 할 때 함수에 여러 인자를 넣어줄 수 있도록 합니다\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores 만큼 쪼개진 데이터를 전처리하여 반환합니다\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "  texts = []\n",
    "  for s in sentences:\n",
    "    texts += preprocess_sentence(s, remove_stopwords),\n",
    "  return texts\n",
    "\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "  start_time = time.time()\n",
    "  num_cores = mp.cpu_count()  # 컴퓨터의 코어 수를 구합니다\n",
    "\n",
    "  text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬적으로 처리할 수 있게 합니다\n",
    "  pool = Pool(num_cores)\n",
    "\n",
    "  processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split))  # 각자 작업한 데이터를 하나로 합쳐줍니다\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(time.time() - start_time, \" seconds\")\n",
    "  return processed_data\n",
    "\n",
    "clean_text = preprocess_data(data['text'])  # 클라우드 기준으로 3~4분 정도 소요 됩니다\n",
    "print(clean_text)\n",
    "\n",
    "clean_summary = preprocess_data(data['headlines'], remove_stopwords=False) # 클라우드 기준 1분정도 소요됩니다.\n",
    "print(clean_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "annoying-edward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치가 생겼는지 확인\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "enclosed-month",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-azerbaijan",
   "metadata": {},
   "source": [
    "## 훈련데이터와 테스트데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "attempted-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 91\n",
      "텍스트의 평균 길이 : 58.23813542090281\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 18\n",
      "요약의 평균 길이 : 9.553660024400163\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headline_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headline_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headline_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headline_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(headline_len)\n",
    "plt.title('headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headline_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "liquid-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 65\n",
    "text_min_len = 45\n",
    "headlines_max_len = 15\n",
    "headlines_min_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "convenient-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, min_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if (len(s.split()) >= min_len) & (len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print(f'전체 샘플 중 길이가 {min_len}이상 {max_len}이하인 샘플의 비율: {cnt/len(nested_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hourly-margin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 45이상 65이하인 샘플의 비율: 0.9997254981699878\n",
      "전체 샘플 중 길이가 5이상 15이하인 샘플의 비율: 0.9997356649044327\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, text_min_len, data['text'])\n",
    "below_threshold_len(headlines_max_len, headlines_min_len, data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "boxed-authority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98345\n"
     ]
    }
   ],
   "source": [
    "# 전체 샘플 중 text데이터의 길이가 45dltkd 65이하인 샘플만 사용\n",
    "# 전체 샘플 중 headlines데이터의 길이가 5이상 15이하인 샘플만 사용\n",
    "\n",
    "data2 = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data2= data[data['text'].apply(lambda x: len(x.split()) >= text_min_len)]\n",
    "\n",
    "data2 = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "data2 = data[data['headlines'].apply(lambda x: len(x.split()) >= headlines_min_len)]\n",
    "\n",
    "print('전체 샘플수 :', (len(data2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-dialogue",
   "metadata": {},
   "source": [
    "## 시작토큰 종료토큰 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rational-johnston",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "      <td>sostoken upGrad learner switches to career in ...</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "      <td>sostoken Delhi techie wins free food from Swig...</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "      <td>sostoken New Zealand end Rohit Sharma-led Indi...</td>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "      <td>sostoken Aegon life iTerm insurance plan helps...</td>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "      <td>sostoken Have known Hirani for yrs, what if Me...</td>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
       "1  Kunal Shah's credit card bill payment platform...   \n",
       "2  New Zealand defeated India by 8 wickets in the...   \n",
       "3  With Aegon Life iTerm Insurance plan, customer...   \n",
       "4  Speaking about the sexual harassment allegatio...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upGrad learner switches to career in ...   \n",
       "1  sostoken Delhi techie wins free food from Swig...   \n",
       "2  sostoken New Zealand end Rohit Sharma-led Indi...   \n",
       "3  sostoken Aegon life iTerm insurance plan helps...   \n",
       "4  sostoken Have known Hirani for yrs, what if Me...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upGrad learner switches to career in ML & Al w...  \n",
       "1  Delhi techie wins free food from Swiggy for on...  \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...  \n",
       "3  Aegon life iTerm insurance plan helps customer...  \n",
       "4  Have known Hirani for yrs, what if MeToo claim...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['decoder_input'] = data2['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data2['decoder_target'] = data2['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "romance-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data2['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data2['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data2['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "alone-photography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56121 44579 79147 ...  9284 84350 64171]\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터, 테스트 데이터 분리\n",
    "\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fuzzy-connectivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19669\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "scheduled-combining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78676\n",
      "훈련 레이블의 개수 : 78676\n",
      "테스트 데이터의 개수 : 19669\n",
      "테스트 레이블의 개수 : 19669\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-values",
   "metadata": {},
   "source": [
    "##  단어집합 만들기, 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-scotland",
   "metadata": {},
   "source": [
    "### text 데이터의 단어집합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "czech-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "every-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 88934\n",
      "등장 빈도가 24번 이하인 희귀 단어의 수: 77158\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11776\n",
      "단어 집합에서 희귀 단어의 비율: 86.75871994962556\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.125576883042776\n"
     ]
    }
   ],
   "source": [
    "threshold = 25\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "alert-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 12000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 12,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "suitable-clerk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7699, 24, 7386, 5, 11016, 6, 10113, 9431, 1904, 4, 1952, 2246, 6, 1533, 768, 12, 3, 1956, 2612, 22, 1614, 16, 1037, 108, 69, 5, 235, 1423, 1, 1904, 6, 5509, 2852, 872, 471, 1111, 59, 5457, 2, 3, 219, 3789, 22, 2604, 2090, 16, 1365, 1735, 2404, 310, 446, 2246, 8, 2424, 164, 111, 9432], [5978, 5282, 1461, 1227, 679, 1637, 550, 744, 205, 3, 2623, 2, 326, 509, 469, 20, 6496, 10, 63, 30, 9729, 3, 86, 4044, 35, 3267, 18, 2908, 3185, 5177, 205, 196, 63, 3993, 206, 2981, 5, 679, 667, 33, 83, 25, 178, 2, 4834, 11251, 20, 4012, 96, 2777, 6, 116], [74, 1039, 968, 38, 15, 301, 830, 4, 1, 743, 379, 22, 5414, 7, 138, 2, 326, 45, 48, 159, 5, 1, 158, 159, 379, 242, 38, 372, 24, 199, 159, 145, 1008, 3460, 5819, 18, 247, 1487, 6937, 1499, 263, 2, 537, 174, 1, 159, 1872, 38, 614, 67, 72, 10, 4131, 45, 2731, 2964, 453, 4, 379, 197, 630]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-pocket",
   "metadata": {},
   "source": [
    "### headlines 데이터의 단어집합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hydraulic-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efficient-ukraine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 40215\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 29009\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11206\n",
      "단어 집합에서 희귀 단어의 비율: 72.13477558125078\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.032716139378918\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "progressive-wilson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 5236, 9375, 3, 903, 4, 9376, 2117, 8, 1217, 1181, 1182], [1, 29, 3955, 167, 277, 397, 14, 3303, 5, 137, 41, 7], [1, 42, 1362, 360, 518, 674, 515, 95, 202, 171, 667, 3160], [1, 8704, 201, 8705, 1839, 524, 981, 1991, 910, 411], [1, 59, 2261, 2907, 5, 142, 160, 81, 1000, 196, 104, 21, 2962, 775]]\n",
      "target\n",
      "decoder  [[5236, 9375, 3, 903, 4, 9376, 2117, 8, 1217, 1181, 1182, 2], [29, 3955, 167, 277, 397, 14, 3303, 5, 137, 41, 7, 2], [42, 1362, 360, 518, 674, 515, 95, 202, 171, 667, 3160, 2], [8704, 201, 8705, 1839, 524, 981, 1991, 910, 411, 2], [59, 2261, 2907, 5, 142, 160, 81, 1000, 196, 104, 21, 2962, 775, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 12000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-period",
   "metadata": {},
   "source": [
    "### 훈련데이터와 테스트데이터에서 요약문의 길이가 1인 경우 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "behavioral-badge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78676\n",
      "훈련 레이블의 개수 : 78676\n",
      "테스트 데이터의 개수 : 19669\n",
      "테스트 레이블의 개수 : 19669\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "peaceful-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-proxy",
   "metadata": {},
   "source": [
    "# 모델 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-coverage",
   "metadata": {},
   "source": [
    "## 인코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "italian-madagascar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-lunch",
   "metadata": {},
   "source": [
    "## 디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "whole-sapphire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-anchor",
   "metadata": {},
   "source": [
    "## 디코더의 출력층 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "advance-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 65, 128)      1536000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 65, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 65, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1536000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 65, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 12000)  3084000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 7,995,104\n",
      "Trainable params: 7,995,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-listing",
   "metadata": {},
   "source": [
    "## 어텐션 메커니즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "entitled-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "elementary-given",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 65, 128)      1536000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 65, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 65, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1536000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 65, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 12000)  6156000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 11,198,432\n",
      "Trainable params: 11,198,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-queen",
   "metadata": {},
   "source": [
    "# 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-bookmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "154/154 [==============================] - 227s 1s/step - loss: 5.5913 - val_loss: 4.4690\n",
      "Epoch 2/25\n",
      "154/154 [==============================] - 214s 1s/step - loss: 4.6630 - val_loss: 4.2633\n",
      "Epoch 3/25\n",
      "154/154 [==============================] - 215s 1s/step - loss: 4.3829 - val_loss: 4.0481\n",
      "Epoch 4/25\n",
      "154/154 [==============================] - 218s 1s/step - loss: 4.1219 - val_loss: 3.8569\n",
      "Epoch 5/25\n",
      "154/154 [==============================] - 221s 1s/step - loss: 3.9050 - val_loss: 3.7237\n",
      "Epoch 6/25\n",
      "154/154 [==============================] - 224s 1s/step - loss: 3.7115 - val_loss: 3.6047\n",
      "Epoch 7/25\n",
      "154/154 [==============================] - 216s 1s/step - loss: 3.5598 - val_loss: 3.5308\n",
      "Epoch 8/25\n",
      "154/154 [==============================] - 221s 1s/step - loss: 3.4319 - val_loss: 3.4660\n",
      "Epoch 9/25\n",
      "154/154 [==============================] - 223s 1s/step - loss: 3.3210 - val_loss: 3.4117\n",
      "Epoch 10/25\n",
      "154/154 [==============================] - 214s 1s/step - loss: 3.2229 - val_loss: 3.3695\n",
      "Epoch 11/25\n",
      "154/154 [==============================] - 214s 1s/step - loss: 3.1325 - val_loss: 3.3299\n",
      "Epoch 12/25\n",
      "154/154 [==============================] - 214s 1s/step - loss: 3.0533 - val_loss: 3.2851\n",
      "Epoch 13/25\n",
      "154/154 [==============================] - 214s 1s/step - loss: 2.9753 - val_loss: 3.2691\n",
      "Epoch 14/25\n",
      "154/154 [==============================] - 213s 1s/step - loss: 2.9035 - val_loss: 3.2330\n",
      "Epoch 15/25\n",
      "154/154 [==============================] - 214s 1s/step - loss: 2.8420 - val_loss: 3.2076\n",
      "Epoch 16/25\n",
      "154/154 [==============================] - 216s 1s/step - loss: 2.7744 - val_loss: 3.1810\n",
      "Epoch 17/25\n",
      "154/154 [==============================] - 217s 1s/step - loss: 2.7199 - val_loss: 3.1742\n",
      "Epoch 18/25\n",
      "154/154 [==============================] - 225s 1s/step - loss: 2.6639 - val_loss: 3.1550\n",
      "Epoch 19/25\n",
      "154/154 [==============================] - 219s 1s/step - loss: 2.6124 - val_loss: 3.1372\n",
      "Epoch 20/25\n",
      "154/154 [==============================] - 216s 1s/step - loss: 2.5638 - val_loss: 3.1386\n",
      "Epoch 21/25\n",
      "154/154 [==============================] - 214s 1s/step - loss: 2.5171 - val_loss: 3.1175\n",
      "Epoch 22/25\n",
      "154/154 [==============================] - 213s 1s/step - loss: 2.4745 - val_loss: 3.1272\n",
      "Epoch 23/25\n",
      "154/154 [==============================] - 215s 1s/step - loss: 2.4373 - val_loss: 3.0995\n",
      "Epoch 24/25\n",
      "154/154 [==============================] - 214s 1s/step - loss: 2.3952 - val_loss: 3.1049\n",
      "Epoch 25/25\n",
      "132/154 [========================>.....] - ETA: 28s - loss: 2.3472"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=512, callbacks=[es], epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-variety",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
